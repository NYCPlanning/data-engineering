name: FacDB - ðŸ—ï¸ Build

on:
  workflow_call:
    inputs:
      run_export:
        type: boolean
        required: true
  workflow_dispatch:
    inputs:
      run_export:
        description: "Run Export Step and Upload to DO"
        type: boolean
        required: true
        default: false

jobs:
  build:
    name: Building ...
    runs-on: ubuntu-22.04
    defaults:
      run:
        shell: bash
        working-directory: products/facilities
    container:
      image: nycplanning/build-geosupport:latest
      env:
        BUILD_ENGINE: postgresql://postgres:postgres@postgis:5432/postgres
        EDM_DATA: ${{ secrets.EDM_DATA }}
    services:
      postgis:
        image: postgis/postgis:15-3.3-alpine
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          --shm-size=2gb
        ports:
          - 5432:5432
    steps:
      - uses: actions/checkout@v3

      - name: Load Secrets
        uses: 1password/load-secrets-action@v1
        with:
          export-env: true
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
          AWS_S3_ENDPOINT: "op://Data Engineering/DO_keys/AWS_S3_ENDPOINT"
          AWS_SECRET_ACCESS_KEY: "op://Data Engineering/DO_keys/AWS_SECRET_ACCESS_KEY"
          AWS_ACCESS_KEY_ID: "op://Data Engineering/DO_keys/AWS_ACCESS_KEY_ID"

      - name: Run Container Setup
        working-directory: ./
        run: ./bash/docker_container_setup.sh

      - name: Initialize
        run: python -m facdb.cli init

      - name: Dataloading
        run: python -m facdb.cli dataloading

      - name: Run Pipelines
        run: python -m facdb.cli run --sql

      - name: Build facdb
        run: python -m facdb.cli build

      - name: QAQC facdb
        run: python -m facdb.cli qaqc

      - name: Export facdb
        run: ./facdb.sh export

      - name: Upload Artifacts
        run: ./facdb.sh upload
