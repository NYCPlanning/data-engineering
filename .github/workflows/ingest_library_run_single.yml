name: Ingest Migration Tool (Single run)
run-name: "Ingest Migration Tool (Single run): ${{ inputs.dataset }} with ${{ inputs.tool }}"

on:
  workflow_dispatch:
    inputs:
      dataset:
        description: "Name of the dataset (required)"
        required: true
      tool:
        description: "Which tool to use for extraction (required)"
        required: true
        type: choice
        options:
          - library
          - ingest
      schema_name:
        description: "Schema name where to store data tables (required)"
        required: true
      version:
        description: "The version of the dataset (i.e. 22v2, 21C) if needed (optional)"
        required: false

jobs:
  dataloading:
    runs-on: ubuntu-22.04
    container:
      image: nycplanning/build-base:latest
    defaults:
      run:
        shell: bash
    env:
      BUILD_NAME: ${{ inputs.schema_name }}
      RECIPES_BUCKET: edm-recipes
      PUBLISHING_BUCKET: edm-publishing
    steps:
      - uses: actions/checkout@v4

      - name: Load Secrets
        uses: 1password/load-secrets-action@v1
        with:
          export-env: true
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
          AWS_S3_ENDPOINT: "op://Data Engineering/DO_keys/AWS_S3_ENDPOINT"
          AWS_SECRET_ACCESS_KEY: "op://Data Engineering/DO_keys/AWS_SECRET_ACCESS_KEY"
          AWS_ACCESS_KEY_ID: "op://Data Engineering/DO_keys/AWS_ACCESS_KEY_ID"
          BUILD_ENGINE_SERVER: "op://Data Engineering/EDM_DATA/server_url"
          SOCRATA_USER: "op://Data Engineering/DCP_OpenData/username"
          SOCRATA_PASSWORD: "op://Data Engineering/DCP_OpenData/password"

      - name: Finish container setup ...
        run: ./bash/docker_container_setup.sh

      # TODO: run CLI to ingest dataset 