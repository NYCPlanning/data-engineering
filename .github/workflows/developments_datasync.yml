name: DevDB - Data Sync and Geocoding of HPD and DOB Data

on:
  schedule:
    - cron: "0 0 * * MON"
  workflow_dispatch:
    inputs:
      version:
        description: "Would you like to specify a version for dob_jobapplications?"
        required: false
        default: "latest"

jobs:
  sync:
    name: syncing
    runs-on: ubuntu-22.04
    env:
      AWS_S3_BUCKET: edm-recipes
    strategy:
      matrix:
        dataset:
          - dob_permitissuance
          - dob_jobapplications
          - hpd_hny_units_by_building
    steps:
      - uses: actions/checkout@v3

      - name: Load Secrets
        uses: 1password/load-secrets-action@v1
        with:
          export-env: true
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
          AWS_S3_ENDPOINT: "op://Data Engineering/DO_keys/AWS_S3_ENDPOINT"
          AWS_SECRET_ACCESS_KEY: "op://Data Engineering/DO_keys/AWS_SECRET_ACCESS_KEY"
          AWS_ACCESS_KEY_ID: "op://Data Engineering/DO_keys/AWS_ACCESS_KEY_ID"

      - uses: NYCPlanning/action-library-archive@v1.1
        with:
          # name of the dataset
          name: ${{ matrix.dataset }}
          path: products/developments/templates/${{ matrix.dataset }}.yml
          s3: true
          latest: true
          compress: true
          output_format: csv pgdump

  geocode:
    name: geocoding
    needs: sync
    services:
      db:
        image: postgis/postgis:15-3.3-alpine
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    runs-on: ubuntu-22.04
    defaults:
      run:
        shell: bash
        working-directory: products/developments
    env:
      AWS_S3_BUCKET: edm-recipes
      BUILD_ENGINE: postgresql://postgres:postgres@localhost:5432/postgres
    steps:
      - uses: actions/checkout@v3

      - name: Load Secrets
        uses: 1password/load-secrets-action@v1
        with:
          export-env: true
        env:
          OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
          AWS_S3_ENDPOINT: "op://Data Engineering/DO_keys/AWS_S3_ENDPOINT"
          AWS_SECRET_ACCESS_KEY: "op://Data Engineering/DO_keys/AWS_SECRET_ACCESS_KEY"
          AWS_ACCESS_KEY_ID: "op://Data Engineering/DO_keys/AWS_ACCESS_KEY_ID"

      - name: Load to Database
        run: |
          ./devdb.sh import hpd_hny_units_by_building ${{ github.event.inputs.version }}
          ./devdb.sh import hpd_historical_units_by_building
          ./devdb.sh import dob_jobapplications
          ./devdb.sh import dob_now_applications

      - name: Geocode
        # Also combines the imported DOB datasets
        run: ./devdb.sh geocode

      - name: Export to csv
        run: |
          ./devdb.sh output hny_geocode_results csv
          ./devdb.sh output hpd_historical_geocode_results csv
          ./devdb.sh output dob_geocode_results csv

      - name: Check file existence
        run: ls *.csv

      - name: Archive to Data Library
        run: |
          ./devdb.sh library_archive hny_geocode_results hpd_hny_units_by_building
          ./devdb.sh library_archive hpd_historical_geocode_results hpd_historical_units_by_building
          ./devdb.sh library_archive dob_geocode_results dob_jobapplications ${{ github.event.inputs.version }}
