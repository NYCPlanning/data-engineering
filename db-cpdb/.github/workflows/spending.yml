name: Archive Capital Spending Data

on:
  workflow_dispatch:

jobs:
  scrape:
    timeout-minutes: 720
    runs-on: ubuntu-22.04
    services:
      postgres:
        image: postgis/postgis:15-3.3-alpine
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    env:
      BUILD_ENGINE: postgresql://postgres:postgres@localhost:5432/postgres
      AWS_S3_ENDPOINT: ${{ secrets.DO_S3_ENDPOINT }}
      AWS_ACCESS_KEY_ID: ${{ secrets.DO_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.DO_SECRET_ACCESS_KEY }}
      AWS_S3_BUCKET: edm-recipes
    steps:
      - uses: actions/checkout@v3

      - name: install dependencies ...
        run: |
          curl -O https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x mc
          sudo mv ./mc /usr/bin
          mc config host add spaces $AWS_S3_ENDPOINT $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY --api S3v4

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true

      - name: Copy the Latest fisa capital commitment to biquery
        run: ./bash/11_spending.sh

      - name: Archive to Data Library -- pgdump and csv
        run: |
          ./bash/11_spending.sh archive csv
          ./bash/11_spending.sh archive pgdump
