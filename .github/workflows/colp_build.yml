name: COLP - 🏗️ Build
on: 
  workflow_call:
    inputs:
      run_export:
        type: boolean
        required: true
      image_tag:
        type: string
        required: false

jobs:
  build:
    name: Build COLP
    runs-on: ubuntu-22.04
    defaults:
      run:
        shell: bash
        working-directory: products/colp
    container: 
      image: nycplanning/build-geosupport:${{ inputs.image_tag || 'latest' }}
    env:
      BUILD_ENGINE_SERVER: ${{ secrets.SQL_ENGINE_EDM_DATA_SERVER }}
      BUILD_ENGINE_DB: db-colp
      BUILD_ENGINE_SCHEMA: ${{ github.head_ref || github.ref_name }}
    services:
      postgis:
        image: postgis/postgis:15-3.3-alpine
        env:
          POSTGRES_DB: dbcolp
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
    - uses: actions/checkout@v3

    - name: Load Secrets
      uses: 1password/load-secrets-action@v1
      with:
        export-env: true
      env:
        OP_SERVICE_ACCOUNT_TOKEN: ${{ secrets.OP_SERVICE_ACCOUNT_TOKEN }}
        AWS_S3_ENDPOINT: "op://Data Engineering/DO_keys/AWS_S3_ENDPOINT"
        AWS_SECRET_ACCESS_KEY: "op://Data Engineering/DO_keys/AWS_SECRET_ACCESS_KEY"
        AWS_ACCESS_KEY_ID: "op://Data Engineering/DO_keys/AWS_ACCESS_KEY_ID"

    - name: Finish container setup ...
      working-directory: ./
      run: ./bash/docker_container_setup.sh

    - name: Set build environment variables
      working-directory: ./
      run: ./bash/build_env_setup.sh

    - name: Dataloading ...
      run: python -m dcpy.builds.load recipe

    - name: Build COLP ...
      run: ./colp.sh build

    - name: Run QAQC ...
      run: ./colp.sh qaqc

    - name: Export COLP ...
      if: inputs.run_export
      run: ./colp.sh export

    - name: Upload outputs to s3 ...
      if: inputs.run_export
      run: ./colp.sh upload
