{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "from dcpy.utils import duckdb as dcpduckdb\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = Path(\"ztl.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the database if it exists\n",
    "DB_PATH.unlink(missing_ok=True)\n",
    "\n",
    "# create the database with extensions and credentials\n",
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    connection.sql(f\"INSTALL spatial\")\n",
    "    connection.sql(f\"LOAD spatial\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    dcpduckdb.setup_s3_secret(DB_PATH)\n",
    "    connection.sql(\n",
    "        \"DESCRIBE TABLE 's3://edm-recipes/datasets/dof_dtm/20241122/dof_dtm.parquet'\"\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `dof_dtm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    dcpduckdb.setup_s3_secret(DB_PATH)\n",
    "    connection.sql(\n",
    "        \"\"\"\n",
    "            create table dof_dtm_old as\n",
    "            select * from\n",
    "            read_parquet(\n",
    "                's3://edm-recipes/datasets/dof_dtm/20241122/dof_dtm.parquet',\n",
    "                filename = true\n",
    "            )\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    dcpduckdb.setup_s3_secret(DB_PATH)\n",
    "    connection.sql(\n",
    "        \"\"\"\n",
    "            create table dof_dtm_new as\n",
    "            select * from\n",
    "            read_parquet(\n",
    "                's3://edm-recipes/datasets/dof_dtm/20250110/dof_dtm.parquet',\n",
    "                filename = true\n",
    "            )\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    connection.sql(\"SHOW ALL TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    connection.sql(\"describe table dof_dtm_old\").show(max_rows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    connection.sql(\"select * from dof_dtm_old\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    connection.sql(\"select * from dof_dtm_new\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    dof_dtm_old = connection.sql(\n",
    "        \"select bbl, wkb_geometry from dof_dtm_old order by bbl asc\"\n",
    "    ).df()\n",
    "dof_dtm_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect(str(DB_PATH)) as connection:\n",
    "    dof_dtm_new = connection.sql(\n",
    "        \"select bbl, wkb_geometry from dof_dtm_new order by bbl asc\"\n",
    "    ).df()\n",
    "dof_dtm_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data_raw = dof_dtm_old\n",
    "new_data_raw = dof_dtm_new\n",
    "INDEX_COLUMN = \"bbl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_data(old_data: pd.DataFrame, new_data: pd.DataFrame) -> None:\n",
    "    print(\"PREVIEW OLD DATA\")\n",
    "    print(old_data.head().to_markdown())\n",
    "    old_data.info()\n",
    "    print(\"PREVIEW NEW DATA\")\n",
    "    new_data.info()\n",
    "    print(new_data.head().to_markdown())\n",
    "\n",
    "    compare_result = old_data.compare(new_data, align_axis=0, keep_equal=True)\n",
    "    rows_with_diff_count = len(compare_result) // 2\n",
    "\n",
    "    if rows_with_diff_count == 0:\n",
    "        print(f\"Files are identical ({len(old_data)} rows)\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"\"\"\n",
    "            Files aren't identical in\n",
    "                {rows_with_diff_count:,} rows out of\n",
    "                {len(old_data):,} rows in old data\n",
    "                {len(new_data):,} rows in new data\n",
    "            \"\"\"\n",
    "        )\n",
    "        compare_result = compare_result.set_index(\n",
    "            compare_result.index.set_names([\"old_data\", \"new_data\"], level=1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_with_unique_indices(\n",
    "    old_data: pd.DataFrame,\n",
    "    new_data: pd.DataFrame,\n",
    "    index_column: str,\n",
    ") -> None:\n",
    "    unique_indices_from_old = set(old_data[index_column].unique()).difference(\n",
    "        set(new_data[index_column].unique())\n",
    "    )\n",
    "    print(\"Unique rows in OLD DATA\")\n",
    "    print(old_data[old_data[index_column].isin(unique_indices_from_old)].to_markdown())\n",
    "    unique_indices_from_new = set(new_data[index_column].unique()).difference(\n",
    "        set(old_data[index_column].unique())\n",
    "    )\n",
    "    print(\"Unique rows in NEW DATA\")\n",
    "    print(new_data[new_data[index_column].isin(unique_indices_from_new)].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_rows_to_compare(\n",
    "    old_data: pd.DataFrame,\n",
    "    new_data: pd.DataFrame,\n",
    "    index_column: str,\n",
    "    common_indices: set,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    columns_to_use = old_data.columns\n",
    "    if len(old_data.columns) > len(new_data.columns):\n",
    "        print(\"!! old data has more columns\")\n",
    "        columns_to_use = new_data.columns\n",
    "    elif len(new_data.columns) > len(old_data.columns):\n",
    "        print(\"!! new data has more columns\")\n",
    "        columns_to_use = old_data.columns\n",
    "\n",
    "    old_data = old_data[columns_to_use]\n",
    "    new_data = new_data[columns_to_use]\n",
    "    columns_to_sort_by = columns_to_use.to_list()\n",
    "\n",
    "    old_data_limited = (\n",
    "        old_data[old_data[index_column].isin(common_indices)]\n",
    "        .sort_values(by=columns_to_sort_by)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    new_data_limited = (\n",
    "        new_data[new_data[index_column].isin(common_indices)]\n",
    "        .sort_values(by=columns_to_sort_by)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return old_data_limited, new_data_limited\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(old_data_raw) == len(new_data_raw):\n",
    "      compare_data(old_data=old_data_raw, new_data=new_data_raw)\n",
    "else:\n",
    "    print(\"WARNING! Can only compare data of the same length and indices!\")\n",
    "    print(\n",
    "        f\"\"\"\n",
    "            {len(old_data_raw):,} rows in old data\n",
    "            {len(new_data_raw):,} rows in new data\n",
    "        \"\"\"\n",
    "    )\n",
    "    print(\"detail differences ...\")\n",
    "    show_data_with_unique_indices(old_data_raw, new_data_raw, INDEX_COLUMN)\n",
    "    common_indices = set(old_data_raw[INDEX_COLUMN].unique()).intersection(\n",
    "        set(new_data_raw[INDEX_COLUMN].unique())\n",
    "    )\n",
    "\n",
    "    print(\"compare common rows ...\")\n",
    "    print(f\"{len(common_indices)} common index values\")\n",
    "    old_data_to_compare, new_data_to_compare = limit_rows_to_compare(\n",
    "        old_data_raw, new_data_raw, INDEX_COLUMN, common_indices\n",
    "    )\n",
    "    compare_data(old_data_to_compare, new_data_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_de_repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
